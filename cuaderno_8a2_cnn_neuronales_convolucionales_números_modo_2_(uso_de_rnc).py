# -*- coding: utf-8 -*-
"""Cuaderno 8A2: CNN neuronales convolucionales - Números - Modo 2 (Uso de RNC)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12svnt9Pkf5Ubsm-ZlXJFeZPlptS9MDru

![imagen](https://images.datacamp.com/image/upload/v1700043905/image10_f8b261ebf1.png)
"""

!python -V

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras.callbacks import EarlyStopping
import math

print(tf.__version__)
print(tfds.__version__)

# Descargar set de datos de MNIST (números escritos a mano, etiquetados)
datos, metadatos = tfds.load('mnist', as_supervised=True, with_info=True)

# Obtener en variables separadas los datos de entrenamiento (60k) y pruebas (10k)
datos_entrenamiento, datos_pruebas = datos['train'], datos['test']

# Función de normalización para los datos (pasar valores de los píxeles de 0-255 a 0-1)
def normalizar(imagenes, etiquetas):
    imagenes = tf.cast(imagenes, tf.float32) / 255.0  # Normalizar a [0, 1]
    imagenes = tf.expand_dims(imagenes, axis=-1)  # Añadir el canal de profundidad
    return imagenes, etiquetas

# Normalizar los datos de entrenamiento y prueba
datos_entrenamiento = datos_entrenamiento.map(normalizar)
datos_pruebas = datos_pruebas.map(normalizar)


# Agregar a cache (usar memoria en lugar de disco, entrenamiento más rápido)
datos_entrenamiento = datos_entrenamiento.cache()
datos_pruebas = datos_pruebas.cache()
clases = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']

#Codigo para mostrar imagenes del set, no es necesario ejecutarlo, solo imprime unos numeros :)
import matplotlib.pyplot as plt

plt.figure(figsize=(10,10))

for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):
  imagen = imagen.numpy().reshape((28,28))
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(imagen, cmap=plt.cm.binary_r)
  plt.xlabel(clases[etiqueta])

plt.show()

"""Este es un modelo de red neuronal convolucional (CNN) diseñado para trabajar con imágenes de 28x28 píxeles, como las del conjunto de datos MNIST. El modelo consta de varias capas, que son:

**Capa de entrada (Input):** Define la forma de entrada de las imágenes. En este caso, las imágenes son en escala de grises con una dimensión de (28, 28, 1).


**Capas de convolución (Conv2D):**


**Conv2D(32, (3, 3), activation='relu'):**

32: Número de filtros (kernels). Cada filtro aprenderá a detectar características diferentes en las imágenes.
(3, 3): Tamaño del kernel. Es un filtro de 3x3 píxeles.
activation='relu': Función de activación que introduce no linealidad.

**Capas de agrupamiento (MaxPooling2D):**

MaxPooling2D((2, 2)): Esta capa reduce las dimensiones espaciales de la salida de la capa anterior. En este caso, se aplica un agrupamiento de 2x2, que toma el valor máximo en cada ventana de 2x2, reduciendo así la resolución.
Capa de aplanamiento (Flatten): Convierte la salida de las capas anteriores en un vector unidimensional para que pueda ser procesado por las capas densas.

![image](https://miro.medium.com/v2/resize:fit:1400/0*QIvqCOigRiq1Gmnc.png)

**Capas densas (Dense):**

La primera capa densa tiene 100 unidades y usa la activación ReLU.
La última capa densa tiene 10 unidades (una por cada clase en el conjunto de datos MNIST) y usa la activación softmax para obtener probabilidades.
Determinación de los Kernels

Los kernels (o filtros) en las capas de convolución son matrices pequeñas que se deslizan (convolucionan) sobre la imagen de entrada para extraer características. Aquí hay algunos puntos clave sobre su determinación y uso:

**Tamaño del Kernel:**

En este caso, el kernel tiene un tamaño de (3, 3). Este tamaño se elige a menudo en función de las características que se desean detectar. Kernels más pequeños (como 3x3 o 5x5) son comunes porque pueden capturar patrones locales de manera efectiva.
Número de Filtros:

En Conv2D(32, ...), el número 32 indica que se están utilizando 32 filtros diferentes. Cada filtro se entrena para aprender diferentes características de la imagen (bordes, texturas, etc.).
Entrenamiento:


Los valores de los kernels son parámetros que se ajustan durante el entrenamiento del modelo. Al inicio, los valores se inicializan aleatoriamente, y durante el entrenamiento, a través del proceso de retropropagación, se ajustan en función del error del modelo.



"""

#Crear el modelo (Ya utiliza capas de convolución y agrupación)
#Cuenta con 1 capa de convolución con 32 núcleos y otra con 64. 2 capas de agrupación.
#Finalmente una capa densa con 100 neuronas
# Crear el modelo
modelo = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(28, 28, 1)),  # Usar Input para definir la forma de entrada
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2), padding="same"),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding="same"),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dense(units=32, activation='relu'),
    tf.keras.layers.Dense(units=10, activation='softmax')
])


# Compilar el modelo
modelo.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

modelo.summary()

# Trabajar por lotes
TAMANO_LOTE = 32

# Shuffle y repeat hacen que los datos estén mezclados de manera aleatoria
# para que el entrenamiento no se aprenda en orden
datos_entrenamiento = datos_entrenamiento.shuffle(10000).batch(TAMANO_LOTE).repeat()
datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)

# Configurar EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Realizar el entrenamiento
num_datos_entrenamiento = metadatos.splits['train'].num_examples
num_datos_entrenamiento

# Realizar el entrenamiento
historial = modelo.fit(
    datos_entrenamiento,
    epochs=50,
    steps_per_epoch=math.ceil(num_datos_entrenamiento / TAMANO_LOTE),
    validation_data=datos_pruebas,
    validation_steps=math.ceil(len(list(datos_pruebas)) / TAMANO_LOTE),
    callbacks=[early_stopping]
)

# Guardar el modelo en el formato nativo de Keras
modelo.save('numerosC2.keras')
#modelo.save('numerosC2.h5')

model_json = modelo.to_json()
with open('numeros2.json', 'w') as json_file:
    json_file.write(model_json)
modelo.save_weights('numeros2.weights.h5') # Change the file name to end with .weights.h5

#Exportar el modelo al explorador! (Mas detalle de esto en en mi video de exportacion: https://youtu.be/JpE4bYyRADI )
#modelo.save('numeros_conv.h5')

#Convertirlo a tensorflow.js
#!pip install tensorflowjs

#!mkdir carpeta_salida

#!tensorflowjs_converter --input_format keras numeros_conv.h5 carpeta_salida

# Print the final training and validation accuracy
print("Final Training Accuracy: {:.4f}".format(historial.history['accuracy'][-1]))
print("Final Validation Accuracy: {:.4f}".format(historial.history['val_accuracy'][-1]))

"""## Descargar Imagen

"""

import requests

url = "https://raw.githubusercontent.com/adiacla/bigdata/refs/heads/master/numero7a.jpg"
response = requests.get(url)

if response.status_code == 200:
    with open("numero2.jpg", "wb") as f:
        f.write(response.content)
    print("Image downloaded successfully as numero2.jpg")
else:
    print(f"Failed to download image. Status code: {response.status_code}")

#mostrar imagen en colab
from IPython.display import Image
Image(filename='numero2.jpg')

"""## Preprocesamiento de la imagen

"""

import cv2
import numpy as np

# Load the image in grayscale
image_path = 'numero2.jpg'
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# Resize the image to 28x28
image_resized = cv2.resize(image, (28, 28))

# Normalize the pixel values to [0, 1]
image_normalized = image_resized.astype(np.float32) / 255.0

# Add a channel dimension
image_preprocessed = np.expand_dims(image_normalized, axis=-1)

# Add a batch dimension (the model expects a batch of images)
image_preprocessed = np.expand_dims(image_preprocessed, axis=0)

print("Image preprocessed successfully. Shape:", image_preprocessed.shape)

"""## Predecir el digito



"""

# Use the trained model to predict the digit
predictions = modelo.predict(image_preprocessed)

# Get the predicted digit (index with the highest probability)
predicted_digit = np.argmax(predictions)

print(f"The predicted digit is: {predicted_digit}")

"""## Desplegamos la predicción


"""

print(f"The predicted digit is: {predicted_digit}")

# Extraer métricas del historial
acc = historial.history['accuracy']
val_acc = historial.history['val_accuracy']
loss = historial.history['loss']
val_loss = historial.history['val_loss']

epocas = range(1, len(acc) + 1)

# Gráfica de precisión
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(epocas, acc, 'b-', label='Entrenamiento')
plt.plot(epocas, val_acc, 'r-', label='Validación')
plt.title('Precisión')
plt.xlabel('Épocas')
plt.ylabel('Accuracy')
plt.legend()

# Gráfica de pérdida
plt.subplot(1, 2, 2)
plt.plot(epocas, loss, 'b-', label='Entrenamiento')
plt.plot(epocas, val_loss, 'r-', label='Validación')
plt.title('Pérdida')
plt.xlabel('Épocas')
plt.ylabel('Loss')
plt.legend()

plt.show()